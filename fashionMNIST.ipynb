{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "name": "fashionMNIST.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fitting-mechanics"
      },
      "source": [
        "### Fashion-MNIST "
      ],
      "id": "fitting-mechanics"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ecological-watershed"
      },
      "source": [
        "from tensorflow.keras import utils\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist"
      ],
      "id": "ecological-watershed",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68-tra-JOSJO"
      },
      "source": [
        "!pip install hyperas\r\n",
        "!pip install hyperopt"
      ],
      "id": "68-tra-JOSJO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K0TUMq92LPCl"
      },
      "source": [
        "\r\n",
        "%matplotlib inline\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import numpy as np\r\n",
        "import time\r\n",
        "# https://gist.github.com/greydanus/f6eee59eaf1d90fcb3b534a25362cea4\r\n",
        "# https://stackoverflow.com/a/14434334\r\n",
        "# this function is used to update the plots for each epoch and error\r\n",
        "def plt_dynamic(x, vy, ty, ax, colors=['b']):\r\n",
        "    ax.plot(x, vy, 'b', label=\"Validation Loss\")\r\n",
        "    ax.plot(x, ty, 'r', label=\"Train Loss\")\r\n",
        "    plt.legend()\r\n",
        "    plt.grid()\r\n",
        "    fig.canvas.draw()"
      ],
      "id": "K0TUMq92LPCl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "involved-acting",
        "outputId": "23c6d971-a0fc-45b3-c740-42d1ba407299"
      },
      "source": [
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()"
      ],
      "id": "involved-acting",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bizarre-macintosh",
        "outputId": "a5a550df-473c-461e-c809-e9d5af04cb49"
      },
      "source": [
        "X_train.shape, X_test.shape"
      ],
      "id": "bizarre-macintosh",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((60000, 28, 28), (10000, 28, 28))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "advisory-administrator"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=12345)"
      ],
      "id": "advisory-administrator",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "infrared-northern",
        "outputId": "1e55181d-f872-4912-b230-88f0f077c877"
      },
      "source": [
        "print(X_train.shape[0],X_val.shape[0])"
      ],
      "id": "infrared-northern",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "48000 12000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "composed-atlas"
      },
      "source": [
        "X_train = X_train.reshape(48000, 784)\n",
        "X_val = X_val.reshape(12000, 784)\n",
        "X_test = X_test.reshape(10000, 784)\n",
        "X_train = X_train.astype('float32')\n",
        "X_val = X_val.astype('float32')\n",
        "X_test = X_test.astype('float32')"
      ],
      "id": "composed-atlas",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cultural-bikini"
      },
      "source": [
        "# if we observe the above matrix each cell is having a value between 0-255\n",
        "# before we move to apply machine learning algorithms lets try to normalize the data\n",
        "# X => (X - Xmin)/(Xmax-Xmin) = X/255\n",
        "\n",
        "X_train = X_train/255\n",
        "X_test = X_test/255\n",
        "X_val = X_val/255\n"
      ],
      "id": "cultural-bikini",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tough-princess"
      },
      "source": [
        "# np is numpy\n",
        "# lets convert this into a 10 dimensional vector\n",
        "# ex: consider an image is of class 5 convert it into 5 => [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n",
        "# this conversion needed for MLPs \n",
        "nb_classes = 10 \n",
        "Y_train = utils.to_categorical(y_train, nb_classes)\n",
        "Y_val = utils.to_categorical(y_val, nb_classes)\n",
        "Y_test = utils.to_categorical(y_test, nb_classes)"
      ],
      "id": "tough-princess",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mounted-waste"
      },
      "source": [
        "## Base Model"
      ],
      "id": "mounted-waste"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cleared-sydney"
      },
      "source": [
        "<h2>  Softmax classifier  </h2>"
      ],
      "id": "cleared-sydney"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "electrical-cruise"
      },
      "source": [
        "from tensorflow.keras.models import Sequential \n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout"
      ],
      "id": "electrical-cruise",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flying-competition"
      },
      "source": [
        "# some model parameters\n",
        "\n",
        "output_dim = 10\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "batch_size = 128 \n",
        "nb_epoch = 20"
      ],
      "id": "flying-competition",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "chicken-miami"
      },
      "source": [
        "# start building a model\n",
        "model = Sequential(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
        "model.compile(optimizer='sgd',\n",
        " loss='categorical_crossentropy',\n",
        " metrics=['accuracy'])"
      ],
      "id": "chicken-miami",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GWe_pBoOJ6ZB",
        "outputId": "beea18c7-2de1-4fc0-957c-b5011012ece6"
      },
      "source": [
        "model.summary()"
      ],
      "id": "GWe_pBoOJ6ZB",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_45\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_135 (Dense)            (None, 10)                7850      \n",
            "=================================================================\n",
            "Total params: 7,850\n",
            "Trainable params: 7,850\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rapid-democrat",
        "outputId": "535166a2-a41a-4eeb-aecc-b58922a20313"
      },
      "source": [
        "history = model.fit(X_train, Y_train, steps_per_epoch=500, epochs=nb_epoch, verbose=1, validation_data=(X_val, Y_val)) \n"
      ],
      "id": "rapid-democrat",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 2s 3ms/step - loss: 1.4597 - accuracy: 0.5662 - val_loss: 0.8348 - val_accuracy: 0.7364\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.7959 - accuracy: 0.7481 - val_loss: 0.7150 - val_accuracy: 0.7732\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.7020 - accuracy: 0.7725 - val_loss: 0.6574 - val_accuracy: 0.7944\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6478 - accuracy: 0.7914 - val_loss: 0.6203 - val_accuracy: 0.8035\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.6172 - accuracy: 0.7996 - val_loss: 0.5954 - val_accuracy: 0.8086\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5917 - accuracy: 0.8074 - val_loss: 0.5763 - val_accuracy: 0.8173\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5712 - accuracy: 0.8114 - val_loss: 0.5607 - val_accuracy: 0.8204\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5629 - accuracy: 0.8158 - val_loss: 0.5489 - val_accuracy: 0.8260\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5570 - accuracy: 0.8158 - val_loss: 0.5382 - val_accuracy: 0.8263\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5404 - accuracy: 0.8210 - val_loss: 0.5298 - val_accuracy: 0.8296\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5271 - accuracy: 0.8250 - val_loss: 0.5217 - val_accuracy: 0.8330\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5230 - accuracy: 0.8254 - val_loss: 0.5165 - val_accuracy: 0.8324\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5170 - accuracy: 0.8285 - val_loss: 0.5103 - val_accuracy: 0.8338\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5133 - accuracy: 0.8283 - val_loss: 0.5043 - val_accuracy: 0.8370\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5048 - accuracy: 0.8301 - val_loss: 0.5019 - val_accuracy: 0.8368\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4990 - accuracy: 0.8324 - val_loss: 0.4966 - val_accuracy: 0.8372\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.5031 - accuracy: 0.8287 - val_loss: 0.4915 - val_accuracy: 0.8395\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4893 - accuracy: 0.8374 - val_loss: 0.4876 - val_accuracy: 0.8401\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4860 - accuracy: 0.8364 - val_loss: 0.4854 - val_accuracy: 0.8400\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 1s 3ms/step - loss: 0.4838 - accuracy: 0.8377 - val_loss: 0.4816 - val_accuracy: 0.8427\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "advance-bloom",
        "outputId": "bb45f173-770e-4169-c862-d3f207f3f83c"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0) \n",
        "print('Test loss:', score[0]) \n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "advance-bloom",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.5135301351547241\n",
            "Test accuracy: 0.8269000053405762\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "-Jceo2mYKcKa",
        "outputId": "d165ac4c-aa27-491e-c40b-6a4718b8ab39"
      },
      "source": [
        "fig,ax = plt.subplots(1,1)\r\n",
        "ax.set_xlabel('epoch') ; ax.set_ylabel('Categorical Crossentropy Loss')\r\n",
        "\r\n",
        "# list of epoch numbers\r\n",
        "x = list(range(1,nb_epoch+1))\r\n",
        "\r\n",
        "# print(history.history.keys())\r\n",
        "# dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])\r\n",
        "# history = model_drop.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch, verbose=1, validation_data=(X_test, Y_test))\r\n",
        "\r\n",
        "# we will get val_loss and val_acc only when you pass the paramter validation_data\r\n",
        "# val_loss : validation loss\r\n",
        "# val_acc : validation accuracy\r\n",
        "\r\n",
        "# loss : training loss\r\n",
        "# acc : train accuracy\r\n",
        "# for each key in histrory.histrory we will have a list of length equal to number of epochs\r\n",
        "\r\n",
        "vy = history.history['val_loss']\r\n",
        "ty = history.history['loss']\r\n",
        "plt_dynamic(x, vy, ty, ax)"
      ],
      "id": "-Jceo2mYKcKa",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sticky-original"
      },
      "source": [
        "<b>Base Model has given an accuracy of 82%, but to improve the model we need to know about which are the hyper-parameters we can tune in our dense network</b>"
      ],
      "id": "sticky-original"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KMVvL9J5O-Oi"
      },
      "source": [
        "from hyperopt import Trials, STATUS_OK, tpe\r\n",
        "from hyperas import optim\r\n",
        "from hyperas.distributions import choice, uniform"
      ],
      "id": "KMVvL9J5O-Oi",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3J6CHKePPruU"
      },
      "source": [
        "def data():\r\n",
        "    import keras\r\n",
        "    from tensorflow.keras import utils as np_utils\r\n",
        "    from tensorflow.keras.layers import Dense, Activation, Dropout\r\n",
        "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\r\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train,    y_train, test_size=0.2, random_state=12345)\r\n",
        "    X_train = X_train.reshape(48000, 784)\r\n",
        "    X_val = X_val.reshape(12000, 784)\r\n",
        "    X_train = X_train.astype('float32')\r\n",
        "    X_val = X_val.astype('float32')\r\n",
        "    X_train /= 255\r\n",
        "    X_val /= 255\r\n",
        "    nb_classes = 10\r\n",
        "    Y_train = np_utils.to_categorical(y_train, nb_classes)\r\n",
        "    Y_val = np_utils.to_categorical(y_val, nb_classes)\r\n",
        "    return X_train, Y_train, X_val, Y_val"
      ],
      "id": "3J6CHKePPruU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QnBAQbutP8EW"
      },
      "source": [
        "def model(X_train, Y_train, X_val, Y_val):\r\n",
        "    \r\n",
        "    model = Sequential()\r\n",
        "    \r\n",
        "    model.add(Dense({{choice([128, 256, 512, 1024])}}, input_shape=(784,)))\r\n",
        "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\r\n",
        "    model.add(Dense({{choice([128, 256, 512, 1024])}}))\r\n",
        "    model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n",
        "    model.add(Dropout({{uniform(0, 1)}}))\r\n",
        "\r\n",
        "\r\n",
        "    if {{choice(['two', 'three'])}} == 'three':\r\n",
        "        model.add(Dense({{choice([128, 256, 512, 1024])}}))\r\n",
        "        model.add(Activation({{choice(['relu', 'sigmoid'])}}))\r\n",
        "        model.add(Dropout({{uniform(0, 1)}}))\r\n",
        "        \r\n",
        "    model.add(Dense(10))\r\n",
        "    model.add(Activation('softmax'))\r\n",
        "    adam = keras.optimizers.Adam(lr={{choice([10**-3, 10**-2, 10**-1])}})\r\n",
        "    rmsprop = keras.optimizers.RMSprop(lr={{choice([10**-3, 10**-2, 10**-1])}})\r\n",
        "    sgd = keras.optimizers.SGD(lr={{choice([10**-3, 10**-2, 10**-1])}})\r\n",
        "   \r\n",
        "    choiceval = {{choice(['adam', 'sgd', 'rmsprop'])}}\r\n",
        "    if choiceval == 'adam':\r\n",
        "        optim = adam\r\n",
        "    elif choiceval == 'rmsprop':\r\n",
        "        optim = rmsprop\r\n",
        "    else:\r\n",
        "        optim = sgd\r\n",
        "        \r\n",
        "    model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\r\n",
        "    model.fit(X_train, Y_train,\r\n",
        "              batch_size={{choice([128,256,512])}},\r\n",
        "              epochs=20,\r\n",
        "              verbose=2,\r\n",
        "              validation_data=(X_val, Y_val))\r\n",
        "    score, acc = model.evaluate(X_val, Y_val, verbose=0)\r\n",
        "    print('Validation accuracy:', acc)\r\n",
        "    return {'loss': -acc, 'status': STATUS_OK, 'model': model}"
      ],
      "id": "QnBAQbutP8EW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s0lI577qRsq9"
      },
      "source": [
        "# Install the PyDrive wrapper & import libraries.\r\n",
        "!pip install -U -q PyDrive\r\n",
        "from pydrive.auth import GoogleAuth\r\n",
        "from pydrive.drive import GoogleDrive\r\n",
        "from google.colab import auth\r\n",
        "from oauth2client.client import GoogleCredentials\r\n"
      ],
      "id": "s0lI577qRsq9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pGnElRhRzz_"
      },
      "source": [
        "# Authenticate and create the PyDrive client.\r\n",
        "auth.authenticate_user()\r\n",
        "gauth = GoogleAuth()\r\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\r\n",
        "drive = GoogleDrive(gauth)"
      ],
      "id": "9pGnElRhRzz_",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ldRD1Js2SDQP"
      },
      "source": [
        "# Copy/download the file\r\n",
        "fid = drive.ListFile({'q':\"title='fashionMNIST.ipynb'\"}).GetList()[0]['id']\r\n",
        "f = drive.CreateFile({'id': fid})\r\n",
        "f.GetContentFile('fashionMNIST.ipynb')"
      ],
      "id": "ldRD1Js2SDQP",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TuHh9wSEQRg0",
        "outputId": "7b4b2a6c-c11d-4deb-8d1b-1ad78f71b742"
      },
      "source": [
        "X_train, Y_train, X_val, Y_val = data()\r\n",
        "best_run, best_model = optim.minimize(model=model,\r\n",
        "                                      data=data,\r\n",
        "                                      algo=tpe.suggest,\r\n",
        "                                      max_evals=30,\r\n",
        "                                      trials=Trials(),\r\n",
        "                                      notebook_name='/fashionMNIST')"
      ],
      "id": "TuHh9wSEQRg0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            ">>> Imports:\n",
            "#coding=utf-8\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras import utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import tensorflow as tf\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.datasets import fashion_mnist\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import matplotlib.pyplot as plt\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import numpy as np\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    import time\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from sklearn.model_selection import train_test_split\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.models import Sequential\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.layers import Dense, Activation, Dropout\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperopt import Trials, STATUS_OK, tpe\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas import optim\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from hyperas.distributions import choice, uniform\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras import utils\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from tensorflow.keras.layers import Dense, Activation, Dropout\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.auth import GoogleAuth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from pydrive.drive import GoogleDrive\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from google.colab import auth\n",
            "except:\n",
            "    pass\n",
            "\n",
            "try:\n",
            "    from oauth2client.client import GoogleCredentials\n",
            "except:\n",
            "    pass\n",
            "\n",
            ">>> Hyperas search space:\n",
            "\n",
            "def get_space():\n",
            "    return {\n",
            "        'Dense': hp.choice('Dense', [128, 256, 512, 1024]),\n",
            "        'Activation': hp.choice('Activation', ['relu', 'sigmoid']),\n",
            "        'Dropout': hp.uniform('Dropout', 0, 1),\n",
            "        'Dense_1': hp.choice('Dense_1', [128, 256, 512, 1024]),\n",
            "        'Activation_1': hp.choice('Activation_1', ['relu', 'sigmoid']),\n",
            "        'Dropout_1': hp.uniform('Dropout_1', 0, 1),\n",
            "        'Dropout_2': hp.choice('Dropout_2', ['two', 'three']),\n",
            "        'Dense_2': hp.choice('Dense_2', [128, 256, 512, 1024]),\n",
            "        'Activation_2': hp.choice('Activation_2', ['relu', 'sigmoid']),\n",
            "        'Dropout_3': hp.uniform('Dropout_3', 0, 1),\n",
            "        'lr': hp.choice('lr', [10**-3, 10**-2, 10**-1]),\n",
            "        'lr_1': hp.choice('lr_1', [10**-3, 10**-2, 10**-1]),\n",
            "        'lr_2': hp.choice('lr_2', [10**-3, 10**-2, 10**-1]),\n",
            "        'choiceval': hp.choice('choiceval', ['adam', 'sgd', 'rmsprop']),\n",
            "        'batch_size': hp.choice('batch_size', [128,256,512]),\n",
            "    }\n",
            "\n",
            ">>> Data\n",
            "  1: \n",
            "  2: import keras\n",
            "  3: from tensorflow.keras import utils as np_utils\n",
            "  4: from tensorflow.keras.layers import Dense, Activation, Dropout\n",
            "  5: (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
            "  6: X_train, X_val, y_train, y_val = train_test_split(X_train,    y_train, test_size=0.2, random_state=12345)\n",
            "  7: X_train = X_train.reshape(48000, 784)\n",
            "  8: X_val = X_val.reshape(12000, 784)\n",
            "  9: X_train = X_train.astype('float32')\n",
            " 10: X_val = X_val.astype('float32')\n",
            " 11: X_train /= 255\n",
            " 12: X_val /= 255\n",
            " 13: nb_classes = 10\n",
            " 14: Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
            " 15: Y_val = np_utils.to_categorical(y_val, nb_classes)\n",
            " 16: \n",
            " 17: \n",
            " 18: \n",
            ">>> Resulting replaced keras model:\n",
            "\n",
            "   1: def keras_fmin_fnct(space):\n",
            "   2: \n",
            "   3:     \n",
            "   4:     model = Sequential()\n",
            "   5:     \n",
            "   6:     model.add(Dense(space['Dense'], input_shape=(784,)))\n",
            "   7:     model.add(Activation(space['Activation']))\n",
            "   8:     model.add(Dropout(space['Dropout']))\n",
            "   9:     model.add(Dense(space['Dense_1']))\n",
            "  10:     model.add(Activation(space['Activation_1']))\n",
            "  11:     model.add(Dropout(space['Dropout_1']))\n",
            "  12: \n",
            "  13: \n",
            "  14:     if space['Dropout_2'] == 'three':\n",
            "  15:         model.add(Dense(space['Dense_2']))\n",
            "  16:         model.add(Activation(space['Activation_2']))\n",
            "  17:         model.add(Dropout(space['Dropout_3']))\n",
            "  18:         \n",
            "  19:     model.add(Dense(10))\n",
            "  20:     model.add(Activation('softmax'))\n",
            "  21:     adam = keras.optimizers.Adam(lr=space['lr'])\n",
            "  22:     rmsprop = keras.optimizers.RMSprop(lr=space['lr_1'])\n",
            "  23:     sgd = keras.optimizers.SGD(lr=space['lr_2'])\n",
            "  24:    \n",
            "  25:     choiceval = space['choiceval']\n",
            "  26:     if choiceval == 'adam':\n",
            "  27:         optim = adam\n",
            "  28:     elif choiceval == 'rmsprop':\n",
            "  29:         optim = rmsprop\n",
            "  30:     else:\n",
            "  31:         optim = sgd\n",
            "  32:         \n",
            "  33:     model.compile(loss='categorical_crossentropy', metrics=['accuracy'],optimizer=optim)\n",
            "  34:     model.fit(X_train, Y_train,\n",
            "  35:               batch_size=space['batch_size'],\n",
            "  36:               epochs=20,\n",
            "  37:               verbose=2,\n",
            "  38:               validation_data=(X_val, Y_val))\n",
            "  39:     score, acc = model.evaluate(X_val, Y_val, verbose=0)\n",
            "  40:     print('Test accuracy:', acc)\n",
            "  41:     return {'loss': -acc, 'status': STATUS_OK, 'model': model}\n",
            "  42: \n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.8840 - accuracy: 0.7176 - val_loss: 0.4444 - val_accuracy: 0.8438\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.4809 - accuracy: 0.8207 - val_loss: 0.5405 - val_accuracy: 0.7931\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.4374 - accuracy: 0.8384 - val_loss: 0.6712 - val_accuracy: 0.7762\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.4134 - accuracy: 0.8487 - val_loss: 0.4511 - val_accuracy: 0.8294\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3969 - accuracy: 0.8569 - val_loss: 0.4140 - val_accuracy: 0.8564\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3882 - accuracy: 0.8607 - val_loss: 0.3575 - val_accuracy: 0.8712\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3719 - accuracy: 0.8654 - val_loss: 0.3747 - val_accuracy: 0.8715\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.3708 - accuracy: 0.8667 - val_loss: 0.3921 - val_accuracy: 0.8714\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.3579 - accuracy: 0.8713 - val_loss: 0.4270 - val_accuracy: 0.8698\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3513 - accuracy: 0.8743 - val_loss: 0.4205 - val_accuracy: 0.8654\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.3525 - accuracy: 0.8749 - val_loss: 0.4148 - val_accuracy: 0.8737\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.3481 - accuracy: 0.8754 - val_loss: 0.4161 - val_accuracy: 0.8748\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.3446 - accuracy: 0.8797 - val_loss: 0.3964 - val_accuracy: 0.8699\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.3359 - accuracy: 0.8792 - val_loss: 0.4794 - val_accuracy: 0.8821\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.3414 - accuracy: 0.8807 - val_loss: 0.4257 - val_accuracy: 0.8789\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.3340 - accuracy: 0.8820 - val_loss: 0.4134 - val_accuracy: 0.8781\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.3399 - accuracy: 0.8795 - val_loss: 0.3958 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.3374 - accuracy: 0.8821 - val_loss: 0.4487 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.3298 - accuracy: 0.8840 - val_loss: 0.4435 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.3338 - accuracy: 0.8847 - val_loss: 0.4472 - val_accuracy: 0.8840\n",
            "\n",
            "Test accuracy:\n",
            "0.8840000033378601\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 1.9850 - accuracy: 0.3161 - val_loss: 1.0249 - val_accuracy: 0.6497\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 1.3963 - accuracy: 0.4265 - val_loss: 0.9459 - val_accuracy: 0.5726\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 1.3222 - accuracy: 0.4631 - val_loss: 0.8305 - val_accuracy: 0.6913\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 1.2915 - accuracy: 0.4792 - val_loss: 0.9028 - val_accuracy: 0.6378\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 1.2560 - accuracy: 0.4968 - val_loss: 0.9048 - val_accuracy: 0.6377\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 1.2402 - accuracy: 0.5013 - val_loss: 0.8440 - val_accuracy: 0.6826\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 1.2302 - accuracy: 0.5102 - val_loss: 0.8521 - val_accuracy: 0.6646\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 1.2372 - accuracy: 0.5088 - val_loss: 0.8677 - val_accuracy: 0.6595\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 1.2166 - accuracy: 0.5154 - val_loss: 0.7715 - val_accuracy: 0.7082\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 1.1980 - accuracy: 0.5194 - val_loss: 0.8451 - val_accuracy: 0.6365\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 1.1917 - accuracy: 0.5254 - val_loss: 0.7939 - val_accuracy: 0.6958\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 1.1948 - accuracy: 0.5250 - val_loss: 0.8091 - val_accuracy: 0.6970\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 1.1816 - accuracy: 0.5275 - val_loss: 0.8001 - val_accuracy: 0.6929\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 1.1770 - accuracy: 0.5327 - val_loss: 0.8298 - val_accuracy: 0.6910\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 1.1693 - accuracy: 0.5380 - val_loss: 0.7808 - val_accuracy: 0.6647\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 1.1705 - accuracy: 0.5338 - val_loss: 0.8079 - val_accuracy: 0.6867\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 1.1672 - accuracy: 0.5336 - val_loss: 0.7804 - val_accuracy: 0.6721\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 1.1699 - accuracy: 0.5362 - val_loss: 0.7966 - val_accuracy: 0.7006\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 1.1604 - accuracy: 0.5365 - val_loss: 0.7829 - val_accuracy: 0.7054\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 1.1544 - accuracy: 0.5392 - val_loss: 0.7696 - val_accuracy: 0.7094\n",
            "\n",
            "Test accuracy:\n",
            "0.7094166874885559\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 3.8823 - accuracy: 0.0973 - val_loss: 2.3100 - val_accuracy: 0.0913\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 2.3872 - accuracy: 0.0971 - val_loss: 2.3087 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 2.3646 - accuracy: 0.1029 - val_loss: 2.3058 - val_accuracy: 0.1003\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 2.3291 - accuracy: 0.1028 - val_loss: 2.3102 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 2.3262 - accuracy: 0.0996 - val_loss: 2.3056 - val_accuracy: 0.1003\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 2.3245 - accuracy: 0.1018 - val_loss: 2.3101 - val_accuracy: 0.0971\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 2.3301 - accuracy: 0.0979 - val_loss: 2.3100 - val_accuracy: 0.1023\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 2.3239 - accuracy: 0.1002 - val_loss: 2.3066 - val_accuracy: 0.0913\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 2.3174 - accuracy: 0.0999 - val_loss: 2.3074 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 2.3166 - accuracy: 0.1008 - val_loss: 2.3105 - val_accuracy: 0.0913\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 2.3178 - accuracy: 0.1000 - val_loss: 2.3053 - val_accuracy: 0.1023\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 2.3222 - accuracy: 0.0998 - val_loss: 2.3058 - val_accuracy: 0.0978\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 2.3131 - accuracy: 0.0982 - val_loss: 2.3112 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 2.3160 - accuracy: 0.1016 - val_loss: 2.3044 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 2.3358 - accuracy: 0.0997 - val_loss: 2.3094 - val_accuracy: 0.0971\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 2.3282 - accuracy: 0.0976 - val_loss: 2.3140 - val_accuracy: 0.0913\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 2.3155 - accuracy: 0.1011 - val_loss: 2.3050 - val_accuracy: 0.1003\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 2.3351 - accuracy: 0.0986 - val_loss: 2.3060 - val_accuracy: 0.0978\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 2.3228 - accuracy: 0.0997 - val_loss: 2.3034 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 2.3148 - accuracy: 0.1009 - val_loss: 2.3069 - val_accuracy: 0.0913\n",
            "\n",
            "Test accuracy:\n",
            "0.09125000238418579\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 2.3460 - accuracy: 0.1112 - val_loss: 2.2620 - val_accuracy: 0.3125\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 2.2858 - accuracy: 0.1392 - val_loss: 2.2191 - val_accuracy: 0.4942\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 2.2410 - accuracy: 0.1716 - val_loss: 2.1737 - val_accuracy: 0.5828\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 2.1929 - accuracy: 0.2053 - val_loss: 2.1264 - val_accuracy: 0.5817\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 2.1445 - accuracy: 0.2405 - val_loss: 2.0748 - val_accuracy: 0.5854\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 2.0919 - accuracy: 0.2804 - val_loss: 2.0185 - val_accuracy: 0.6015\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 2.0332 - accuracy: 0.3197 - val_loss: 1.9574 - val_accuracy: 0.5982\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 1.9702 - accuracy: 0.3552 - val_loss: 1.8923 - val_accuracy: 0.6242\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 1.9019 - accuracy: 0.3881 - val_loss: 1.8234 - val_accuracy: 0.6187\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 1.8342 - accuracy: 0.4124 - val_loss: 1.7550 - val_accuracy: 0.6399\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 1.7687 - accuracy: 0.4375 - val_loss: 1.6864 - val_accuracy: 0.6230\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 1.7008 - accuracy: 0.4584 - val_loss: 1.6210 - val_accuracy: 0.6201\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 1.6400 - accuracy: 0.4772 - val_loss: 1.5592 - val_accuracy: 0.6343\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 1.5806 - accuracy: 0.4947 - val_loss: 1.5021 - val_accuracy: 0.6228\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 1.5275 - accuracy: 0.5096 - val_loss: 1.4493 - val_accuracy: 0.6306\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 1.4756 - accuracy: 0.5260 - val_loss: 1.4015 - val_accuracy: 0.6368\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 1.4315 - accuracy: 0.5340 - val_loss: 1.3587 - val_accuracy: 0.6489\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 1.3912 - accuracy: 0.5442 - val_loss: 1.3193 - val_accuracy: 0.6567\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 1.3532 - accuracy: 0.5547 - val_loss: 1.2834 - val_accuracy: 0.6482\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 1.3166 - accuracy: 0.5691 - val_loss: 1.2504 - val_accuracy: 0.6618\n",
            "\n",
            "Test accuracy:\n",
            "0.6618333458900452\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 3.1555 - accuracy: 0.1018 - val_loss: 2.3000 - val_accuracy: 0.1034\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 3.0591 - accuracy: 0.1027 - val_loss: 2.2953 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 2.9977 - accuracy: 0.1053 - val_loss: 2.2850 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 2.9335 - accuracy: 0.1052 - val_loss: 2.2717 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 2.8794 - accuracy: 0.1100 - val_loss: 2.2607 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 2.8275 - accuracy: 0.1142 - val_loss: 2.2511 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 2.8015 - accuracy: 0.1137 - val_loss: 2.2431 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 2.7612 - accuracy: 0.1131 - val_loss: 2.2366 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 2.7253 - accuracy: 0.1177 - val_loss: 2.2316 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 2.6839 - accuracy: 0.1202 - val_loss: 2.2271 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 2.6720 - accuracy: 0.1186 - val_loss: 2.2227 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 2.6355 - accuracy: 0.1219 - val_loss: 2.2193 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 2.6241 - accuracy: 0.1215 - val_loss: 2.2165 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 2.5851 - accuracy: 0.1279 - val_loss: 2.2138 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 2.5665 - accuracy: 0.1276 - val_loss: 2.2112 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 2.5528 - accuracy: 0.1293 - val_loss: 2.2086 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 2.5304 - accuracy: 0.1281 - val_loss: 2.2066 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 2.5082 - accuracy: 0.1332 - val_loss: 2.2043 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 2.4960 - accuracy: 0.1345 - val_loss: 2.2019 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 2.4724 - accuracy: 0.1380 - val_loss: 2.1997 - val_accuracy: 0.1033\n",
            "\n",
            "Test accuracy:\n",
            "0.10333333164453506\n",
            "Epoch 1/20\n",
            "375/375 - 2s - loss: 348.6733 - accuracy: 0.1569 - val_loss: 2.3103 - val_accuracy: 0.1003\n",
            "\n",
            "Epoch 2/20\n",
            "375/375 - 1s - loss: 3.3990 - accuracy: 0.1002 - val_loss: 2.3115 - val_accuracy: 0.0971\n",
            "\n",
            "Epoch 3/20\n",
            "375/375 - 1s - loss: 3.2944 - accuracy: 0.1060 - val_loss: 2.3198 - val_accuracy: 0.0996\n",
            "\n",
            "Epoch 4/20\n",
            "375/375 - 1s - loss: 2.5541 - accuracy: 0.0997 - val_loss: 2.3119 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 5/20\n",
            "375/375 - 1s - loss: 3.1287 - accuracy: 0.1042 - val_loss: 2.3025 - val_accuracy: 0.1038\n",
            "\n",
            "Epoch 6/20\n",
            "375/375 - 1s - loss: 2.4693 - accuracy: 0.1002 - val_loss: 2.3079 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 7/20\n",
            "375/375 - 1s - loss: 2.7587 - accuracy: 0.0992 - val_loss: 2.3060 - val_accuracy: 0.1030\n",
            "\n",
            "Epoch 8/20\n",
            "375/375 - 1s - loss: 2.6206 - accuracy: 0.1013 - val_loss: 2.3156 - val_accuracy: 0.0986\n",
            "\n",
            "Epoch 9/20\n",
            "375/375 - 1s - loss: 2.6805 - accuracy: 0.1048 - val_loss: 2.2874 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 10/20\n",
            "375/375 - 1s - loss: 2.7482 - accuracy: 0.1078 - val_loss: 2.2908 - val_accuracy: 0.1185\n",
            "\n",
            "Epoch 11/20\n",
            "375/375 - 1s - loss: 3.2753 - accuracy: 0.1134 - val_loss: 2.2925 - val_accuracy: 0.1067\n",
            "\n",
            "Epoch 12/20\n",
            "375/375 - 1s - loss: 3.0670 - accuracy: 0.1128 - val_loss: 2.3487 - val_accuracy: 0.1079\n",
            "\n",
            "Epoch 13/20\n",
            "375/375 - 1s - loss: 3.2995 - accuracy: 0.1142 - val_loss: 2.2726 - val_accuracy: 0.0982\n",
            "\n",
            "Epoch 14/20\n",
            "375/375 - 1s - loss: 3.1276 - accuracy: 0.1057 - val_loss: 2.2823 - val_accuracy: 0.1176\n",
            "\n",
            "Epoch 15/20\n",
            "375/375 - 1s - loss: 2.3750 - accuracy: 0.1118 - val_loss: 2.2559 - val_accuracy: 0.1128\n",
            "\n",
            "Epoch 16/20\n",
            "375/375 - 1s - loss: 3.2141 - accuracy: 0.1289 - val_loss: 2.2809 - val_accuracy: 0.1184\n",
            "\n",
            "Epoch 17/20\n",
            "375/375 - 1s - loss: 2.9346 - accuracy: 0.1215 - val_loss: 2.8707 - val_accuracy: 0.1146\n",
            "\n",
            "Epoch 18/20\n",
            "375/375 - 1s - loss: 2.8305 - accuracy: 0.1461 - val_loss: 2.2633 - val_accuracy: 0.1292\n",
            "\n",
            "Epoch 19/20\n",
            "375/375 - 1s - loss: 2.4931 - accuracy: 0.1445 - val_loss: 2.1022 - val_accuracy: 0.2146\n",
            "\n",
            "Epoch 20/20\n",
            "375/375 - 1s - loss: 2.8105 - accuracy: 0.1762 - val_loss: 2.1990 - val_accuracy: 0.1797\n",
            "\n",
            "Test accuracy:\n",
            "0.179666668176651\n",
            "Epoch 1/20\n",
            "375/375 - 1s - loss: 0.7317 - accuracy: 0.7326 - val_loss: 0.4671 - val_accuracy: 0.8319\n",
            "\n",
            "Epoch 2/20\n",
            "375/375 - 1s - loss: 0.4900 - accuracy: 0.8208 - val_loss: 0.4030 - val_accuracy: 0.8568\n",
            "\n",
            "Epoch 3/20\n",
            "375/375 - 1s - loss: 0.4407 - accuracy: 0.8380 - val_loss: 0.3705 - val_accuracy: 0.8671\n",
            "\n",
            "Epoch 4/20\n",
            "375/375 - 1s - loss: 0.4123 - accuracy: 0.8485 - val_loss: 0.3637 - val_accuracy: 0.8698\n",
            "\n",
            "Epoch 5/20\n",
            "375/375 - 1s - loss: 0.3917 - accuracy: 0.8576 - val_loss: 0.3398 - val_accuracy: 0.8789\n",
            "\n",
            "Epoch 6/20\n",
            "375/375 - 1s - loss: 0.3768 - accuracy: 0.8606 - val_loss: 0.3342 - val_accuracy: 0.8795\n",
            "\n",
            "Epoch 7/20\n",
            "375/375 - 1s - loss: 0.3622 - accuracy: 0.8657 - val_loss: 0.3256 - val_accuracy: 0.8836\n",
            "\n",
            "Epoch 8/20\n",
            "375/375 - 1s - loss: 0.3542 - accuracy: 0.8695 - val_loss: 0.3177 - val_accuracy: 0.8863\n",
            "\n",
            "Epoch 9/20\n",
            "375/375 - 1s - loss: 0.3438 - accuracy: 0.8724 - val_loss: 0.3148 - val_accuracy: 0.8857\n",
            "\n",
            "Epoch 10/20\n",
            "375/375 - 1s - loss: 0.3357 - accuracy: 0.8756 - val_loss: 0.3145 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 11/20\n",
            "375/375 - 1s - loss: 0.3299 - accuracy: 0.8774 - val_loss: 0.3112 - val_accuracy: 0.8866\n",
            "\n",
            "Epoch 12/20\n",
            "375/375 - 1s - loss: 0.3221 - accuracy: 0.8813 - val_loss: 0.2983 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 13/20\n",
            "375/375 - 1s - loss: 0.3168 - accuracy: 0.8825 - val_loss: 0.3068 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 14/20\n",
            "375/375 - 1s - loss: 0.3099 - accuracy: 0.8862 - val_loss: 0.2916 - val_accuracy: 0.8952\n",
            "\n",
            "Epoch 15/20\n",
            "375/375 - 1s - loss: 0.3051 - accuracy: 0.8875 - val_loss: 0.2993 - val_accuracy: 0.8918\n",
            "\n",
            "Epoch 16/20\n",
            "375/375 - 1s - loss: 0.2995 - accuracy: 0.8893 - val_loss: 0.2916 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 17/20\n",
            "375/375 - 1s - loss: 0.2946 - accuracy: 0.8902 - val_loss: 0.2890 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 18/20\n",
            "375/375 - 1s - loss: 0.2902 - accuracy: 0.8915 - val_loss: 0.2886 - val_accuracy: 0.8951\n",
            "\n",
            "Epoch 19/20\n",
            "375/375 - 1s - loss: 0.2880 - accuracy: 0.8928 - val_loss: 0.2858 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 20/20\n",
            "375/375 - 1s - loss: 0.2847 - accuracy: 0.8950 - val_loss: 0.2815 - val_accuracy: 0.8996\n",
            "\n",
            "Test accuracy:\n",
            "0.8995833396911621\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 4.1582 - accuracy: 0.1031 - val_loss: 2.2952 - val_accuracy: 0.1635\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 2.3424 - accuracy: 0.0982 - val_loss: 2.3000 - val_accuracy: 0.1194\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 2.3187 - accuracy: 0.1016 - val_loss: 2.3005 - val_accuracy: 0.1605\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 2.3222 - accuracy: 0.1040 - val_loss: 2.2947 - val_accuracy: 0.1637\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 2.3168 - accuracy: 0.1023 - val_loss: 2.2604 - val_accuracy: 0.1980\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 2.3205 - accuracy: 0.1004 - val_loss: 2.2438 - val_accuracy: 0.1916\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 2.3121 - accuracy: 0.1017 - val_loss: 2.2436 - val_accuracy: 0.2068\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 2.3135 - accuracy: 0.1004 - val_loss: 2.2387 - val_accuracy: 0.1933\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 2.3348 - accuracy: 0.1018 - val_loss: 2.2684 - val_accuracy: 0.1893\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 2.3212 - accuracy: 0.0996 - val_loss: 2.2700 - val_accuracy: 0.1653\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 2.3170 - accuracy: 0.1011 - val_loss: 2.2786 - val_accuracy: 0.1601\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 2.3297 - accuracy: 0.0997 - val_loss: 2.2707 - val_accuracy: 0.1876\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 2.3221 - accuracy: 0.1014 - val_loss: 2.2588 - val_accuracy: 0.1318\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 2.3034 - accuracy: 0.1001 - val_loss: 2.2656 - val_accuracy: 0.1982\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 2.3241 - accuracy: 0.1007 - val_loss: 2.2876 - val_accuracy: 0.1069\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 2.3073 - accuracy: 0.1013 - val_loss: 2.2805 - val_accuracy: 0.1216\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 2.3011 - accuracy: 0.1028 - val_loss: 2.2712 - val_accuracy: 0.1899\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 2.3121 - accuracy: 0.1004 - val_loss: 2.2773 - val_accuracy: 0.1711\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 2.3204 - accuracy: 0.1015 - val_loss: 2.2185 - val_accuracy: 0.1988\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 2.3048 - accuracy: 0.1011 - val_loss: 2.2200 - val_accuracy: 0.1935\n",
            "\n",
            "Test accuracy:\n",
            "0.19349999725818634\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 3.4221 - accuracy: 0.0981 - val_loss: 2.3761 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 3.3040 - accuracy: 0.0997 - val_loss: 2.3234 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 3.2726 - accuracy: 0.0986 - val_loss: 2.3076 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 3.2384 - accuracy: 0.1009 - val_loss: 2.3025 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 3.2145 - accuracy: 0.1017 - val_loss: 2.3005 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 3.1975 - accuracy: 0.0984 - val_loss: 2.2997 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 3.1672 - accuracy: 0.1029 - val_loss: 2.2992 - val_accuracy: 0.1021\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 3.1591 - accuracy: 0.0988 - val_loss: 2.2987 - val_accuracy: 0.1039\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 3.1309 - accuracy: 0.0999 - val_loss: 2.2981 - val_accuracy: 0.1243\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 3.1098 - accuracy: 0.0997 - val_loss: 2.2978 - val_accuracy: 0.1271\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 3.0990 - accuracy: 0.0994 - val_loss: 2.2975 - val_accuracy: 0.1474\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 3.0728 - accuracy: 0.1017 - val_loss: 2.2972 - val_accuracy: 0.1584\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 3.0568 - accuracy: 0.1001 - val_loss: 2.2969 - val_accuracy: 0.1525\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 3.0463 - accuracy: 0.1020 - val_loss: 2.2967 - val_accuracy: 0.1653\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 3.0174 - accuracy: 0.1015 - val_loss: 2.2963 - val_accuracy: 0.1522\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 2.9996 - accuracy: 0.1007 - val_loss: 2.2960 - val_accuracy: 0.1599\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 2.9909 - accuracy: 0.0997 - val_loss: 2.2957 - val_accuracy: 0.1620\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 2.9766 - accuracy: 0.1000 - val_loss: 2.2956 - val_accuracy: 0.1857\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 2.9669 - accuracy: 0.0974 - val_loss: 2.2954 - val_accuracy: 0.1866\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 2.9412 - accuracy: 0.0999 - val_loss: 2.2950 - val_accuracy: 0.2082\n",
            "\n",
            "Test accuracy:\n",
            "0.2081666737794876\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 2.1816 - accuracy: 0.1698 - val_loss: 1.7423 - val_accuracy: 0.5470\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 2.0082 - accuracy: 0.2090 - val_loss: 1.6611 - val_accuracy: 0.3730\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 1.9127 - accuracy: 0.2408 - val_loss: 1.5074 - val_accuracy: 0.4142\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 1.8715 - accuracy: 0.2604 - val_loss: 1.4359 - val_accuracy: 0.4793\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 1.8583 - accuracy: 0.2638 - val_loss: 1.4069 - val_accuracy: 0.4902\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 1.8712 - accuracy: 0.2611 - val_loss: 1.3760 - val_accuracy: 0.4358\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 1.8783 - accuracy: 0.2553 - val_loss: 1.4304 - val_accuracy: 0.3864\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 1.8644 - accuracy: 0.2590 - val_loss: 1.4302 - val_accuracy: 0.4275\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 1.8796 - accuracy: 0.2509 - val_loss: 1.2880 - val_accuracy: 0.3747\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 1.8992 - accuracy: 0.2515 - val_loss: 1.5123 - val_accuracy: 0.3392\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 1.9058 - accuracy: 0.2460 - val_loss: 1.3961 - val_accuracy: 0.3655\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 1.8824 - accuracy: 0.2569 - val_loss: 1.4463 - val_accuracy: 0.3611\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 1.8879 - accuracy: 0.2545 - val_loss: 1.4395 - val_accuracy: 0.3997\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 1.9167 - accuracy: 0.2424 - val_loss: 1.4682 - val_accuracy: 0.3916\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 1.9233 - accuracy: 0.2398 - val_loss: 1.5668 - val_accuracy: 0.3396\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 1.9056 - accuracy: 0.2425 - val_loss: 1.4460 - val_accuracy: 0.3652\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 1.9042 - accuracy: 0.2487 - val_loss: 1.4165 - val_accuracy: 0.3916\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 1.9041 - accuracy: 0.2514 - val_loss: 1.3723 - val_accuracy: 0.3919\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 1.8946 - accuracy: 0.2556 - val_loss: 1.4412 - val_accuracy: 0.3840\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 1.9239 - accuracy: 0.2488 - val_loss: 1.6538 - val_accuracy: 0.2609\n",
            "\n",
            "Test accuracy:\n",
            "0.26091668009757996\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 2.8268 - accuracy: 0.1194 - val_loss: 2.3415 - val_accuracy: 0.0910\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 2.8151 - accuracy: 0.1283 - val_loss: 2.4509 - val_accuracy: 0.0980\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 2.8891 - accuracy: 0.1319 - val_loss: 2.3061 - val_accuracy: 0.1933\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 2.8948 - accuracy: 0.1355 - val_loss: 2.2564 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 2.8482 - accuracy: 0.1456 - val_loss: 2.2853 - val_accuracy: 0.2539\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 2.9211 - accuracy: 0.1443 - val_loss: 2.1099 - val_accuracy: 0.1863\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 2.9094 - accuracy: 0.1402 - val_loss: 2.2297 - val_accuracy: 0.1869\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 2.9166 - accuracy: 0.1414 - val_loss: 2.2675 - val_accuracy: 0.1893\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 2.8587 - accuracy: 0.1373 - val_loss: 2.0961 - val_accuracy: 0.2451\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 2.8994 - accuracy: 0.1391 - val_loss: 2.3909 - val_accuracy: 0.2252\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 2.8107 - accuracy: 0.1365 - val_loss: 2.3692 - val_accuracy: 0.1346\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 2.8547 - accuracy: 0.1324 - val_loss: 2.3190 - val_accuracy: 0.1471\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 2.8541 - accuracy: 0.1330 - val_loss: 2.3173 - val_accuracy: 0.1982\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 2.8413 - accuracy: 0.1372 - val_loss: 2.2901 - val_accuracy: 0.1895\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 2.7637 - accuracy: 0.1347 - val_loss: 2.3900 - val_accuracy: 0.1339\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 2.8000 - accuracy: 0.1345 - val_loss: 2.5991 - val_accuracy: 0.0492\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 2.7844 - accuracy: 0.1345 - val_loss: 2.5156 - val_accuracy: 0.1084\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 2.8102 - accuracy: 0.1348 - val_loss: 2.5830 - val_accuracy: 0.1246\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 2.7771 - accuracy: 0.1350 - val_loss: 2.3875 - val_accuracy: 0.0953\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 2.7292 - accuracy: 0.1426 - val_loss: 2.2785 - val_accuracy: 0.1943\n",
            "\n",
            "Test accuracy:\n",
            "0.19425000250339508\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.8628 - accuracy: 0.6892 - val_loss: 0.4883 - val_accuracy: 0.8131\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.5069 - accuracy: 0.8125 - val_loss: 0.4884 - val_accuracy: 0.8205\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.4423 - accuracy: 0.8363 - val_loss: 0.4149 - val_accuracy: 0.8482\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.4041 - accuracy: 0.8509 - val_loss: 0.3698 - val_accuracy: 0.8639\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3794 - accuracy: 0.8610 - val_loss: 0.3631 - val_accuracy: 0.8652\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3606 - accuracy: 0.8677 - val_loss: 0.3568 - val_accuracy: 0.8696\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3464 - accuracy: 0.8720 - val_loss: 0.3277 - val_accuracy: 0.8801\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.3300 - accuracy: 0.8779 - val_loss: 0.3227 - val_accuracy: 0.8828\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.3187 - accuracy: 0.8806 - val_loss: 0.3202 - val_accuracy: 0.8846\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3070 - accuracy: 0.8863 - val_loss: 0.3345 - val_accuracy: 0.8823\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.3015 - accuracy: 0.8879 - val_loss: 0.3025 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.2919 - accuracy: 0.8915 - val_loss: 0.2983 - val_accuracy: 0.8954\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.2843 - accuracy: 0.8935 - val_loss: 0.2911 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.2763 - accuracy: 0.8970 - val_loss: 0.3057 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.2705 - accuracy: 0.8996 - val_loss: 0.2978 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.2651 - accuracy: 0.9002 - val_loss: 0.3067 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.2567 - accuracy: 0.9045 - val_loss: 0.3257 - val_accuracy: 0.8971\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.2511 - accuracy: 0.9055 - val_loss: 0.3100 - val_accuracy: 0.8955\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.2469 - accuracy: 0.9066 - val_loss: 0.3296 - val_accuracy: 0.8813\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2418 - accuracy: 0.9091 - val_loss: 0.2942 - val_accuracy: 0.9015\n",
            "\n",
            "Test accuracy:\n",
            "0.9014999866485596\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 11.2524 - accuracy: 0.1010 - val_loss: 8.6913 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 6.5149 - accuracy: 0.1024 - val_loss: 8.0009 - val_accuracy: 0.0971\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 6.8222 - accuracy: 0.0993 - val_loss: 5.4134 - val_accuracy: 0.0913\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 7.4225 - accuracy: 0.0993 - val_loss: 7.1272 - val_accuracy: 0.1018\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 7.0082 - accuracy: 0.1005 - val_loss: 8.7164 - val_accuracy: 0.1023\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 7.5009 - accuracy: 0.1020 - val_loss: 4.5544 - val_accuracy: 0.1023\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 7.5429 - accuracy: 0.1008 - val_loss: 3.7724 - val_accuracy: 0.1023\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 6.9636 - accuracy: 0.0981 - val_loss: 5.7785 - val_accuracy: 0.1003\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 7.3290 - accuracy: 0.0976 - val_loss: 9.5692 - val_accuracy: 0.1048\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 7.2167 - accuracy: 0.1019 - val_loss: 4.5308 - val_accuracy: 0.1033\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 8.8999 - accuracy: 0.1024 - val_loss: 6.1849 - val_accuracy: 0.1030\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 8.3134 - accuracy: 0.0999 - val_loss: 7.8567 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 7.7226 - accuracy: 0.0984 - val_loss: 5.4509 - val_accuracy: 0.0983\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 6.1693 - accuracy: 0.1013 - val_loss: 5.0260 - val_accuracy: 0.1018\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 7.6461 - accuracy: 0.0987 - val_loss: 4.8271 - val_accuracy: 0.1018\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 8.6493 - accuracy: 0.0989 - val_loss: 6.5023 - val_accuracy: 0.0971\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 6.8011 - accuracy: 0.0992 - val_loss: 3.6930 - val_accuracy: 0.1023\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 5.4844 - accuracy: 0.0977 - val_loss: 5.6334 - val_accuracy: 0.1023\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 6.3466 - accuracy: 0.1022 - val_loss: 8.2759 - val_accuracy: 0.1003\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 7.6855 - accuracy: 0.1000 - val_loss: 9.8393 - val_accuracy: 0.1003\n",
            "\n",
            "Test accuracy:\n",
            "0.1003333330154419\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 2.6618 - accuracy: 0.0995 - val_loss: 2.3313 - val_accuracy: 0.1028\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 2.5741 - accuracy: 0.1019 - val_loss: 2.3111 - val_accuracy: 0.1134\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 2.5437 - accuracy: 0.1109 - val_loss: 2.2881 - val_accuracy: 0.1357\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 2.5201 - accuracy: 0.1148 - val_loss: 2.2618 - val_accuracy: 0.1477\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 2.4883 - accuracy: 0.1182 - val_loss: 2.2408 - val_accuracy: 0.1577\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 2.4734 - accuracy: 0.1240 - val_loss: 2.2208 - val_accuracy: 0.1633\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 2.4495 - accuracy: 0.1270 - val_loss: 2.2004 - val_accuracy: 0.1784\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 2.4235 - accuracy: 0.1352 - val_loss: 2.1786 - val_accuracy: 0.2015\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 2.4083 - accuracy: 0.1383 - val_loss: 2.1609 - val_accuracy: 0.2103\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 2.3811 - accuracy: 0.1460 - val_loss: 2.1435 - val_accuracy: 0.2324\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 2.3615 - accuracy: 0.1499 - val_loss: 2.1249 - val_accuracy: 0.2440\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 2.3382 - accuracy: 0.1534 - val_loss: 2.1079 - val_accuracy: 0.2677\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 2.3241 - accuracy: 0.1612 - val_loss: 2.0897 - val_accuracy: 0.2823\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 2.3077 - accuracy: 0.1636 - val_loss: 2.0742 - val_accuracy: 0.2909\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 2.2865 - accuracy: 0.1710 - val_loss: 2.0560 - val_accuracy: 0.3076\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 2.2651 - accuracy: 0.1750 - val_loss: 2.0377 - val_accuracy: 0.3183\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 2.2531 - accuracy: 0.1806 - val_loss: 2.0225 - val_accuracy: 0.3262\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 2.2350 - accuracy: 0.1871 - val_loss: 2.0065 - val_accuracy: 0.3304\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 2.2207 - accuracy: 0.1911 - val_loss: 1.9900 - val_accuracy: 0.3385\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 2.2003 - accuracy: 0.1966 - val_loss: 1.9729 - val_accuracy: 0.3469\n",
            "\n",
            "Test accuracy:\n",
            "0.34691667556762695\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 2.3953 - accuracy: 0.1091 - val_loss: 2.2630 - val_accuracy: 0.1057\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 2.3498 - accuracy: 0.1233 - val_loss: 2.2252 - val_accuracy: 0.2373\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 2.3082 - accuracy: 0.1381 - val_loss: 2.1848 - val_accuracy: 0.3099\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 2.2595 - accuracy: 0.1579 - val_loss: 2.1298 - val_accuracy: 0.4816\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 2.2050 - accuracy: 0.1811 - val_loss: 2.0645 - val_accuracy: 0.4363\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 2.1394 - accuracy: 0.2096 - val_loss: 1.9899 - val_accuracy: 0.4835\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 2.0610 - accuracy: 0.2398 - val_loss: 1.8963 - val_accuracy: 0.5518\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 0s - loss: 1.9760 - accuracy: 0.2702 - val_loss: 1.7993 - val_accuracy: 0.4942\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 1.8879 - accuracy: 0.2972 - val_loss: 1.7072 - val_accuracy: 0.5366\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 0s - loss: 1.8033 - accuracy: 0.3162 - val_loss: 1.6175 - val_accuracy: 0.5883\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 1.7276 - accuracy: 0.3408 - val_loss: 1.5448 - val_accuracy: 0.5084\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 0s - loss: 1.6582 - accuracy: 0.3596 - val_loss: 1.4699 - val_accuracy: 0.6317\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 1.5976 - accuracy: 0.3796 - val_loss: 1.4120 - val_accuracy: 0.5673\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 1.5482 - accuracy: 0.3926 - val_loss: 1.3596 - val_accuracy: 0.6345\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 1.5024 - accuracy: 0.4112 - val_loss: 1.3153 - val_accuracy: 0.5640\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 1.4573 - accuracy: 0.4250 - val_loss: 1.2753 - val_accuracy: 0.6366\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 1.4201 - accuracy: 0.4386 - val_loss: 1.2375 - val_accuracy: 0.6033\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 1.3867 - accuracy: 0.4521 - val_loss: 1.2045 - val_accuracy: 0.6265\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 1.3580 - accuracy: 0.4617 - val_loss: 1.1761 - val_accuracy: 0.6138\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 1.3314 - accuracy: 0.4744 - val_loss: 1.1521 - val_accuracy: 0.6472\n",
            "\n",
            "Test accuracy:\n",
            "0.6472499966621399\n",
            "Epoch 1/20\n",
            "375/375 - 1s - loss: 1.3211 - accuracy: 0.5547 - val_loss: 0.7824 - val_accuracy: 0.7168\n",
            "\n",
            "Epoch 2/20\n",
            "375/375 - 1s - loss: 0.8315 - accuracy: 0.7110 - val_loss: 0.6489 - val_accuracy: 0.7723\n",
            "\n",
            "Epoch 3/20\n",
            "375/375 - 1s - loss: 0.7241 - accuracy: 0.7471 - val_loss: 0.5908 - val_accuracy: 0.7952\n",
            "\n",
            "Epoch 4/20\n",
            "375/375 - 1s - loss: 0.6604 - accuracy: 0.7725 - val_loss: 0.5494 - val_accuracy: 0.8136\n",
            "\n",
            "Epoch 5/20\n",
            "375/375 - 1s - loss: 0.6245 - accuracy: 0.7833 - val_loss: 0.5209 - val_accuracy: 0.8249\n",
            "\n",
            "Epoch 6/20\n",
            "375/375 - 1s - loss: 0.5927 - accuracy: 0.7921 - val_loss: 0.4976 - val_accuracy: 0.8314\n",
            "\n",
            "Epoch 7/20\n",
            "375/375 - 1s - loss: 0.5716 - accuracy: 0.7998 - val_loss: 0.4805 - val_accuracy: 0.8380\n",
            "\n",
            "Epoch 8/20\n",
            "375/375 - 1s - loss: 0.5535 - accuracy: 0.8074 - val_loss: 0.4645 - val_accuracy: 0.8426\n",
            "\n",
            "Epoch 9/20\n",
            "375/375 - 1s - loss: 0.5369 - accuracy: 0.8117 - val_loss: 0.4551 - val_accuracy: 0.8440\n",
            "\n",
            "Epoch 10/20\n",
            "375/375 - 1s - loss: 0.5249 - accuracy: 0.8173 - val_loss: 0.4418 - val_accuracy: 0.8501\n",
            "\n",
            "Epoch 11/20\n",
            "375/375 - 1s - loss: 0.5115 - accuracy: 0.8189 - val_loss: 0.4364 - val_accuracy: 0.8507\n",
            "\n",
            "Epoch 12/20\n",
            "375/375 - 1s - loss: 0.4996 - accuracy: 0.8244 - val_loss: 0.4270 - val_accuracy: 0.8535\n",
            "\n",
            "Epoch 13/20\n",
            "375/375 - 1s - loss: 0.4932 - accuracy: 0.8257 - val_loss: 0.4207 - val_accuracy: 0.8554\n",
            "\n",
            "Epoch 14/20\n",
            "375/375 - 1s - loss: 0.4828 - accuracy: 0.8277 - val_loss: 0.4128 - val_accuracy: 0.8567\n",
            "\n",
            "Epoch 15/20\n",
            "375/375 - 1s - loss: 0.4740 - accuracy: 0.8323 - val_loss: 0.4071 - val_accuracy: 0.8590\n",
            "\n",
            "Epoch 16/20\n",
            "375/375 - 1s - loss: 0.4691 - accuracy: 0.8330 - val_loss: 0.4032 - val_accuracy: 0.8608\n",
            "\n",
            "Epoch 17/20\n",
            "375/375 - 1s - loss: 0.4626 - accuracy: 0.8354 - val_loss: 0.3942 - val_accuracy: 0.8637\n",
            "\n",
            "Epoch 18/20\n",
            "375/375 - 1s - loss: 0.4567 - accuracy: 0.8381 - val_loss: 0.3907 - val_accuracy: 0.8649\n",
            "\n",
            "Epoch 19/20\n",
            "375/375 - 1s - loss: 0.4465 - accuracy: 0.8409 - val_loss: 0.3860 - val_accuracy: 0.8658\n",
            "\n",
            "Epoch 20/20\n",
            "375/375 - 1s - loss: 0.4412 - accuracy: 0.8420 - val_loss: 0.3831 - val_accuracy: 0.8662\n",
            "\n",
            "Test accuracy:\n",
            "0.8662499785423279\n",
            "Epoch 1/20\n",
            "375/375 - 1s - loss: 2.3771 - accuracy: 0.1191 - val_loss: 2.2623 - val_accuracy: 0.2520\n",
            "\n",
            "Epoch 2/20\n",
            "375/375 - 1s - loss: 2.2432 - accuracy: 0.1583 - val_loss: 2.0808 - val_accuracy: 0.3643\n",
            "\n",
            "Epoch 3/20\n",
            "375/375 - 1s - loss: 2.0194 - accuracy: 0.2363 - val_loss: 1.6259 - val_accuracy: 0.4645\n",
            "\n",
            "Epoch 4/20\n",
            "375/375 - 1s - loss: 1.7508 - accuracy: 0.3005 - val_loss: 1.3796 - val_accuracy: 0.5007\n",
            "\n",
            "Epoch 5/20\n",
            "375/375 - 1s - loss: 1.5815 - accuracy: 0.3486 - val_loss: 1.2569 - val_accuracy: 0.5072\n",
            "\n",
            "Epoch 6/20\n",
            "375/375 - 1s - loss: 1.4700 - accuracy: 0.3908 - val_loss: 1.1724 - val_accuracy: 0.5362\n",
            "\n",
            "Epoch 7/20\n",
            "375/375 - 1s - loss: 1.3887 - accuracy: 0.4187 - val_loss: 1.1132 - val_accuracy: 0.5339\n",
            "\n",
            "Epoch 8/20\n",
            "375/375 - 1s - loss: 1.3262 - accuracy: 0.4524 - val_loss: 1.0589 - val_accuracy: 0.5684\n",
            "\n",
            "Epoch 9/20\n",
            "375/375 - 1s - loss: 1.2732 - accuracy: 0.4756 - val_loss: 1.0271 - val_accuracy: 0.5552\n",
            "\n",
            "Epoch 10/20\n",
            "375/375 - 1s - loss: 1.2267 - accuracy: 0.4927 - val_loss: 0.9898 - val_accuracy: 0.5754\n",
            "\n",
            "Epoch 11/20\n",
            "375/375 - 1s - loss: 1.1923 - accuracy: 0.5084 - val_loss: 0.9617 - val_accuracy: 0.5876\n",
            "\n",
            "Epoch 12/20\n",
            "375/375 - 1s - loss: 1.1607 - accuracy: 0.5238 - val_loss: 0.9374 - val_accuracy: 0.6078\n",
            "\n",
            "Epoch 13/20\n",
            "375/375 - 1s - loss: 1.1331 - accuracy: 0.5404 - val_loss: 0.9137 - val_accuracy: 0.6446\n",
            "\n",
            "Epoch 14/20\n",
            "375/375 - 1s - loss: 1.1004 - accuracy: 0.5530 - val_loss: 0.8895 - val_accuracy: 0.6438\n",
            "\n",
            "Epoch 15/20\n",
            "375/375 - 1s - loss: 1.0787 - accuracy: 0.5609 - val_loss: 0.8696 - val_accuracy: 0.6626\n",
            "\n",
            "Epoch 16/20\n",
            "375/375 - 1s - loss: 1.0545 - accuracy: 0.5734 - val_loss: 0.8527 - val_accuracy: 0.6546\n",
            "\n",
            "Epoch 17/20\n",
            "375/375 - 1s - loss: 1.0325 - accuracy: 0.5869 - val_loss: 0.8278 - val_accuracy: 0.6573\n",
            "\n",
            "Epoch 18/20\n",
            "375/375 - 1s - loss: 1.0104 - accuracy: 0.5953 - val_loss: 0.8105 - val_accuracy: 0.6593\n",
            "\n",
            "Epoch 19/20\n",
            "375/375 - 1s - loss: 0.9921 - accuracy: 0.6043 - val_loss: 0.7899 - val_accuracy: 0.7018\n",
            "\n",
            "Epoch 20/20\n",
            "375/375 - 1s - loss: 0.9757 - accuracy: 0.6100 - val_loss: 0.7771 - val_accuracy: 0.7019\n",
            "\n",
            "Test accuracy:\n",
            "0.7019166946411133\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.8509 - accuracy: 0.6979 - val_loss: 0.5070 - val_accuracy: 0.8146\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.5241 - accuracy: 0.8102 - val_loss: 0.4235 - val_accuracy: 0.8478\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.4602 - accuracy: 0.8355 - val_loss: 0.4087 - val_accuracy: 0.8524\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.4267 - accuracy: 0.8473 - val_loss: 0.3719 - val_accuracy: 0.8661\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.4033 - accuracy: 0.8540 - val_loss: 0.3517 - val_accuracy: 0.8693\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3852 - accuracy: 0.8598 - val_loss: 0.3486 - val_accuracy: 0.8739\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3709 - accuracy: 0.8640 - val_loss: 0.3492 - val_accuracy: 0.8712\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.3598 - accuracy: 0.8697 - val_loss: 0.3663 - val_accuracy: 0.8620\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.3466 - accuracy: 0.8735 - val_loss: 0.3330 - val_accuracy: 0.8803\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3396 - accuracy: 0.8753 - val_loss: 0.3230 - val_accuracy: 0.8826\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.3310 - accuracy: 0.8782 - val_loss: 0.3450 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.3229 - accuracy: 0.8831 - val_loss: 0.3121 - val_accuracy: 0.8888\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.3192 - accuracy: 0.8827 - val_loss: 0.3067 - val_accuracy: 0.8888\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.3112 - accuracy: 0.8862 - val_loss: 0.3142 - val_accuracy: 0.8872\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.3046 - accuracy: 0.8872 - val_loss: 0.3003 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.3030 - accuracy: 0.8879 - val_loss: 0.3166 - val_accuracy: 0.8843\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.2938 - accuracy: 0.8921 - val_loss: 0.3047 - val_accuracy: 0.8902\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.2898 - accuracy: 0.8929 - val_loss: 0.3077 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.2868 - accuracy: 0.8931 - val_loss: 0.3110 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2813 - accuracy: 0.8965 - val_loss: 0.2980 - val_accuracy: 0.8926\n",
            "\n",
            "Test accuracy:\n",
            "0.8925833106040955\n",
            "Epoch 1/20\n",
            "94/94 - 1s - loss: 2.8518 - accuracy: 0.1013 - val_loss: 2.3181 - val_accuracy: 0.1098\n",
            "\n",
            "Epoch 2/20\n",
            "94/94 - 0s - loss: 2.7075 - accuracy: 0.1051 - val_loss: 2.3102 - val_accuracy: 0.1447\n",
            "\n",
            "Epoch 3/20\n",
            "94/94 - 0s - loss: 2.6451 - accuracy: 0.1094 - val_loss: 2.2938 - val_accuracy: 0.1341\n",
            "\n",
            "Epoch 4/20\n",
            "94/94 - 0s - loss: 2.6053 - accuracy: 0.1110 - val_loss: 2.2795 - val_accuracy: 0.1355\n",
            "\n",
            "Epoch 5/20\n",
            "94/94 - 0s - loss: 2.5683 - accuracy: 0.1140 - val_loss: 2.2693 - val_accuracy: 0.1384\n",
            "\n",
            "Epoch 6/20\n",
            "94/94 - 0s - loss: 2.5394 - accuracy: 0.1150 - val_loss: 2.2599 - val_accuracy: 0.1419\n",
            "\n",
            "Epoch 7/20\n",
            "94/94 - 0s - loss: 2.5017 - accuracy: 0.1192 - val_loss: 2.2522 - val_accuracy: 0.1461\n",
            "\n",
            "Epoch 8/20\n",
            "94/94 - 0s - loss: 2.4769 - accuracy: 0.1252 - val_loss: 2.2466 - val_accuracy: 0.1579\n",
            "\n",
            "Epoch 9/20\n",
            "94/94 - 0s - loss: 2.4578 - accuracy: 0.1250 - val_loss: 2.2423 - val_accuracy: 0.1682\n",
            "\n",
            "Epoch 10/20\n",
            "94/94 - 0s - loss: 2.4372 - accuracy: 0.1272 - val_loss: 2.2384 - val_accuracy: 0.1791\n",
            "\n",
            "Epoch 11/20\n",
            "94/94 - 0s - loss: 2.4189 - accuracy: 0.1298 - val_loss: 2.2364 - val_accuracy: 0.1972\n",
            "\n",
            "Epoch 12/20\n",
            "94/94 - 0s - loss: 2.3942 - accuracy: 0.1336 - val_loss: 2.2352 - val_accuracy: 0.2243\n",
            "\n",
            "Epoch 13/20\n",
            "94/94 - 0s - loss: 2.3826 - accuracy: 0.1377 - val_loss: 2.2341 - val_accuracy: 0.2500\n",
            "\n",
            "Epoch 14/20\n",
            "94/94 - 0s - loss: 2.3710 - accuracy: 0.1367 - val_loss: 2.2321 - val_accuracy: 0.2617\n",
            "\n",
            "Epoch 15/20\n",
            "94/94 - 0s - loss: 2.3573 - accuracy: 0.1409 - val_loss: 2.2297 - val_accuracy: 0.2673\n",
            "\n",
            "Epoch 16/20\n",
            "94/94 - 0s - loss: 2.3423 - accuracy: 0.1432 - val_loss: 2.2273 - val_accuracy: 0.2713\n",
            "\n",
            "Epoch 17/20\n",
            "94/94 - 0s - loss: 2.3289 - accuracy: 0.1474 - val_loss: 2.2229 - val_accuracy: 0.2794\n",
            "\n",
            "Epoch 18/20\n",
            "94/94 - 0s - loss: 2.3270 - accuracy: 0.1463 - val_loss: 2.2183 - val_accuracy: 0.2948\n",
            "\n",
            "Epoch 19/20\n",
            "94/94 - 0s - loss: 2.3095 - accuracy: 0.1525 - val_loss: 2.2133 - val_accuracy: 0.3119\n",
            "\n",
            "Epoch 20/20\n",
            "94/94 - 0s - loss: 2.3046 - accuracy: 0.1529 - val_loss: 2.2080 - val_accuracy: 0.3255\n",
            "\n",
            "Test accuracy:\n",
            "0.3255000114440918\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.6453 - accuracy: 0.7652 - val_loss: 0.4371 - val_accuracy: 0.8372\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.4601 - accuracy: 0.8314 - val_loss: 0.3698 - val_accuracy: 0.8668\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.4203 - accuracy: 0.8448 - val_loss: 0.3459 - val_accuracy: 0.8758\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.4010 - accuracy: 0.8514 - val_loss: 0.3358 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3834 - accuracy: 0.8587 - val_loss: 0.3292 - val_accuracy: 0.8812\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3778 - accuracy: 0.8596 - val_loss: 0.3178 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3646 - accuracy: 0.8648 - val_loss: 0.3420 - val_accuracy: 0.8738\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.3549 - accuracy: 0.8661 - val_loss: 0.3082 - val_accuracy: 0.8884\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.3531 - accuracy: 0.8691 - val_loss: 0.3023 - val_accuracy: 0.8915\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3388 - accuracy: 0.8749 - val_loss: 0.2954 - val_accuracy: 0.8922\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.3393 - accuracy: 0.8728 - val_loss: 0.3110 - val_accuracy: 0.8834\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.3314 - accuracy: 0.8759 - val_loss: 0.2938 - val_accuracy: 0.8915\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.3270 - accuracy: 0.8772 - val_loss: 0.3060 - val_accuracy: 0.8890\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.3205 - accuracy: 0.8799 - val_loss: 0.2862 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.3140 - accuracy: 0.8821 - val_loss: 0.2974 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.3122 - accuracy: 0.8833 - val_loss: 0.2825 - val_accuracy: 0.8969\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.3080 - accuracy: 0.8843 - val_loss: 0.2839 - val_accuracy: 0.8978\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.3067 - accuracy: 0.8848 - val_loss: 0.2762 - val_accuracy: 0.9022\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.3005 - accuracy: 0.8877 - val_loss: 0.2846 - val_accuracy: 0.8949\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2950 - accuracy: 0.8882 - val_loss: 0.2749 - val_accuracy: 0.8997\n",
            "\n",
            "Test accuracy:\n",
            "0.8996666669845581\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.6159 - accuracy: 0.7761 - val_loss: 0.4480 - val_accuracy: 0.8360\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.4201 - accuracy: 0.8453 - val_loss: 0.3604 - val_accuracy: 0.8698\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.3766 - accuracy: 0.8610 - val_loss: 0.3399 - val_accuracy: 0.8756\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.3541 - accuracy: 0.8682 - val_loss: 0.3168 - val_accuracy: 0.8847\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3340 - accuracy: 0.8775 - val_loss: 0.3142 - val_accuracy: 0.8851\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3224 - accuracy: 0.8807 - val_loss: 0.3105 - val_accuracy: 0.8885\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3095 - accuracy: 0.8845 - val_loss: 0.2961 - val_accuracy: 0.8920\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.2994 - accuracy: 0.8872 - val_loss: 0.3166 - val_accuracy: 0.8859\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.2940 - accuracy: 0.8912 - val_loss: 0.3270 - val_accuracy: 0.8788\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.2818 - accuracy: 0.8939 - val_loss: 0.2884 - val_accuracy: 0.8935\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.2763 - accuracy: 0.8949 - val_loss: 0.2899 - val_accuracy: 0.8935\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.2725 - accuracy: 0.8979 - val_loss: 0.2826 - val_accuracy: 0.8991\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.2625 - accuracy: 0.9011 - val_loss: 0.2810 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.2586 - accuracy: 0.9036 - val_loss: 0.2753 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.2566 - accuracy: 0.9051 - val_loss: 0.2751 - val_accuracy: 0.9000\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.2506 - accuracy: 0.9055 - val_loss: 0.2672 - val_accuracy: 0.9068\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.2488 - accuracy: 0.9068 - val_loss: 0.2768 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.2386 - accuracy: 0.9096 - val_loss: 0.2743 - val_accuracy: 0.9019\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.2364 - accuracy: 0.9112 - val_loss: 0.2783 - val_accuracy: 0.9016\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2330 - accuracy: 0.9121 - val_loss: 0.2761 - val_accuracy: 0.9005\n",
            "\n",
            "Test accuracy:\n",
            "0.9004999995231628\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.7257 - accuracy: 0.7305 - val_loss: 0.4617 - val_accuracy: 0.8298\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.4763 - accuracy: 0.8230 - val_loss: 0.4250 - val_accuracy: 0.8481\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.4188 - accuracy: 0.8449 - val_loss: 0.4094 - val_accuracy: 0.8558\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.3828 - accuracy: 0.8587 - val_loss: 0.3539 - val_accuracy: 0.8742\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3644 - accuracy: 0.8652 - val_loss: 0.3423 - val_accuracy: 0.8732\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3466 - accuracy: 0.8716 - val_loss: 0.3120 - val_accuracy: 0.8905\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3306 - accuracy: 0.8791 - val_loss: 0.3100 - val_accuracy: 0.8893\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.3227 - accuracy: 0.8798 - val_loss: 0.3103 - val_accuracy: 0.8827\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.3138 - accuracy: 0.8844 - val_loss: 0.3651 - val_accuracy: 0.8674\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3077 - accuracy: 0.8861 - val_loss: 0.3393 - val_accuracy: 0.8827\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.2992 - accuracy: 0.8888 - val_loss: 0.3244 - val_accuracy: 0.8857\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.2941 - accuracy: 0.8924 - val_loss: 0.2940 - val_accuracy: 0.8956\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.2880 - accuracy: 0.8935 - val_loss: 0.3118 - val_accuracy: 0.8927\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.2833 - accuracy: 0.8972 - val_loss: 0.3055 - val_accuracy: 0.8928\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.2812 - accuracy: 0.8955 - val_loss: 0.2909 - val_accuracy: 0.8934\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.2771 - accuracy: 0.8979 - val_loss: 0.3024 - val_accuracy: 0.8921\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.2717 - accuracy: 0.9006 - val_loss: 0.3022 - val_accuracy: 0.8933\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.2669 - accuracy: 0.9013 - val_loss: 0.3021 - val_accuracy: 0.8974\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.2648 - accuracy: 0.9037 - val_loss: 0.2934 - val_accuracy: 0.8967\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2627 - accuracy: 0.9037 - val_loss: 0.3367 - val_accuracy: 0.8792\n",
            "\n",
            "Test accuracy:\n",
            "0.8791666626930237\n",
            "Epoch 1/20\n",
            "188/188 - 2s - loss: 0.7356 - accuracy: 0.7268 - val_loss: 0.4980 - val_accuracy: 0.8227\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.4781 - accuracy: 0.8233 - val_loss: 0.3694 - val_accuracy: 0.8644\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.4218 - accuracy: 0.8445 - val_loss: 0.3565 - val_accuracy: 0.8688\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.3891 - accuracy: 0.8571 - val_loss: 0.3883 - val_accuracy: 0.8497\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3662 - accuracy: 0.8640 - val_loss: 0.3446 - val_accuracy: 0.8684\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3509 - accuracy: 0.8704 - val_loss: 0.3393 - val_accuracy: 0.8811\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3352 - accuracy: 0.8769 - val_loss: 0.3349 - val_accuracy: 0.8787\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.3241 - accuracy: 0.8813 - val_loss: 0.3513 - val_accuracy: 0.8656\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.3205 - accuracy: 0.8819 - val_loss: 0.3447 - val_accuracy: 0.8821\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3135 - accuracy: 0.8856 - val_loss: 0.3169 - val_accuracy: 0.8887\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.3049 - accuracy: 0.8869 - val_loss: 0.3000 - val_accuracy: 0.8950\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.3007 - accuracy: 0.8899 - val_loss: 0.3567 - val_accuracy: 0.8786\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.2923 - accuracy: 0.8923 - val_loss: 0.3056 - val_accuracy: 0.8924\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.2897 - accuracy: 0.8924 - val_loss: 0.3058 - val_accuracy: 0.8893\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.2817 - accuracy: 0.8973 - val_loss: 0.3304 - val_accuracy: 0.8852\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.2838 - accuracy: 0.8962 - val_loss: 0.2936 - val_accuracy: 0.8939\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.2768 - accuracy: 0.8983 - val_loss: 0.3548 - val_accuracy: 0.8698\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.2734 - accuracy: 0.8999 - val_loss: 0.3017 - val_accuracy: 0.8903\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.2689 - accuracy: 0.9029 - val_loss: 0.3173 - val_accuracy: 0.8913\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2659 - accuracy: 0.9035 - val_loss: 0.3012 - val_accuracy: 0.8967\n",
            "\n",
            "Test accuracy:\n",
            "0.8966666460037231\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.6043 - accuracy: 0.7800 - val_loss: 0.4025 - val_accuracy: 0.8548\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.3994 - accuracy: 0.8538 - val_loss: 0.3670 - val_accuracy: 0.8665\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.3587 - accuracy: 0.8680 - val_loss: 0.3304 - val_accuracy: 0.8830\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.3267 - accuracy: 0.8788 - val_loss: 0.3050 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3088 - accuracy: 0.8857 - val_loss: 0.3245 - val_accuracy: 0.8814\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.2912 - accuracy: 0.8927 - val_loss: 0.3137 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.2807 - accuracy: 0.8960 - val_loss: 0.2975 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.2669 - accuracy: 0.9011 - val_loss: 0.2838 - val_accuracy: 0.8972\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.2569 - accuracy: 0.9052 - val_loss: 0.2772 - val_accuracy: 0.9008\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.2457 - accuracy: 0.9084 - val_loss: 0.2928 - val_accuracy: 0.8941\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.2445 - accuracy: 0.9088 - val_loss: 0.2795 - val_accuracy: 0.8998\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.2308 - accuracy: 0.9133 - val_loss: 0.2799 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.2281 - accuracy: 0.9144 - val_loss: 0.2912 - val_accuracy: 0.8958\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.2184 - accuracy: 0.9191 - val_loss: 0.2805 - val_accuracy: 0.9020\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.2109 - accuracy: 0.9203 - val_loss: 0.2838 - val_accuracy: 0.9015\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.2042 - accuracy: 0.9241 - val_loss: 0.2825 - val_accuracy: 0.9021\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.1988 - accuracy: 0.9246 - val_loss: 0.2763 - val_accuracy: 0.9031\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.1863 - accuracy: 0.9296 - val_loss: 0.2895 - val_accuracy: 0.9029\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.1947 - accuracy: 0.9267 - val_loss: 0.2903 - val_accuracy: 0.9013\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.1814 - accuracy: 0.9323 - val_loss: 0.2970 - val_accuracy: 0.9028\n",
            "\n",
            "Test accuracy:\n",
            "0.9027500152587891\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.6813 - accuracy: 0.7486 - val_loss: 0.3905 - val_accuracy: 0.8630\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.4351 - accuracy: 0.8445 - val_loss: 0.3938 - val_accuracy: 0.8558\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.3824 - accuracy: 0.8602 - val_loss: 0.3630 - val_accuracy: 0.8692\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.3502 - accuracy: 0.8729 - val_loss: 0.3150 - val_accuracy: 0.8848\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3275 - accuracy: 0.8798 - val_loss: 0.3261 - val_accuracy: 0.8816\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3128 - accuracy: 0.8855 - val_loss: 0.3022 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3013 - accuracy: 0.8899 - val_loss: 0.2932 - val_accuracy: 0.8960\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.2857 - accuracy: 0.8951 - val_loss: 0.2816 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.2749 - accuracy: 0.8984 - val_loss: 0.2886 - val_accuracy: 0.8977\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.2669 - accuracy: 0.9020 - val_loss: 0.2767 - val_accuracy: 0.8992\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.2581 - accuracy: 0.9033 - val_loss: 0.2902 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.2500 - accuracy: 0.9079 - val_loss: 0.2869 - val_accuracy: 0.8968\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.2398 - accuracy: 0.9119 - val_loss: 0.2864 - val_accuracy: 0.9007\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.2307 - accuracy: 0.9151 - val_loss: 0.2802 - val_accuracy: 0.9018\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.2265 - accuracy: 0.9163 - val_loss: 0.2832 - val_accuracy: 0.9003\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.2263 - accuracy: 0.9161 - val_loss: 0.2714 - val_accuracy: 0.9034\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.2143 - accuracy: 0.9183 - val_loss: 0.2743 - val_accuracy: 0.9049\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.2112 - accuracy: 0.9219 - val_loss: 0.2865 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.2037 - accuracy: 0.9243 - val_loss: 0.2777 - val_accuracy: 0.9058\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.1999 - accuracy: 0.9257 - val_loss: 0.2923 - val_accuracy: 0.8972\n",
            "\n",
            "Test accuracy:\n",
            "0.8971666693687439\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 1.1111 - accuracy: 0.5837 - val_loss: 0.7030 - val_accuracy: 0.7498\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.7229 - accuracy: 0.7383 - val_loss: 0.5397 - val_accuracy: 0.8105\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.6325 - accuracy: 0.7784 - val_loss: 0.4712 - val_accuracy: 0.8443\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.5789 - accuracy: 0.8013 - val_loss: 0.4598 - val_accuracy: 0.8441\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.5433 - accuracy: 0.8165 - val_loss: 0.4462 - val_accuracy: 0.8509\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.5161 - accuracy: 0.8264 - val_loss: 0.3905 - val_accuracy: 0.8710\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.4940 - accuracy: 0.8328 - val_loss: 0.3863 - val_accuracy: 0.8749\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.4819 - accuracy: 0.8385 - val_loss: 0.4113 - val_accuracy: 0.8658\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.4719 - accuracy: 0.8439 - val_loss: 0.4258 - val_accuracy: 0.8640\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.4582 - accuracy: 0.8486 - val_loss: 0.3734 - val_accuracy: 0.8840\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.4501 - accuracy: 0.8501 - val_loss: 0.3772 - val_accuracy: 0.8818\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.4390 - accuracy: 0.8560 - val_loss: 0.4321 - val_accuracy: 0.8577\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.4360 - accuracy: 0.8580 - val_loss: 0.3615 - val_accuracy: 0.8860\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.4287 - accuracy: 0.8594 - val_loss: 0.3986 - val_accuracy: 0.8760\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.4170 - accuracy: 0.8629 - val_loss: 0.3947 - val_accuracy: 0.8789\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.4148 - accuracy: 0.8654 - val_loss: 0.4614 - val_accuracy: 0.8611\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.4101 - accuracy: 0.8679 - val_loss: 0.3489 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.4036 - accuracy: 0.8696 - val_loss: 0.3367 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.4051 - accuracy: 0.8700 - val_loss: 0.3440 - val_accuracy: 0.8942\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.3979 - accuracy: 0.8712 - val_loss: 0.3574 - val_accuracy: 0.8913\n",
            "\n",
            "Test accuracy:\n",
            "0.8913333415985107\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 1.0432 - accuracy: 0.5982 - val_loss: 0.5553 - val_accuracy: 0.7797\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.6347 - accuracy: 0.7637 - val_loss: 0.5019 - val_accuracy: 0.8152\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.5546 - accuracy: 0.7998 - val_loss: 0.4405 - val_accuracy: 0.8397\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.5086 - accuracy: 0.8176 - val_loss: 0.4133 - val_accuracy: 0.8543\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.4764 - accuracy: 0.8309 - val_loss: 0.3919 - val_accuracy: 0.8572\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.4512 - accuracy: 0.8405 - val_loss: 0.3620 - val_accuracy: 0.8723\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.4349 - accuracy: 0.8466 - val_loss: 0.3585 - val_accuracy: 0.8748\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.4193 - accuracy: 0.8517 - val_loss: 0.3526 - val_accuracy: 0.8749\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.4083 - accuracy: 0.8545 - val_loss: 0.3492 - val_accuracy: 0.8813\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3982 - accuracy: 0.8590 - val_loss: 0.3459 - val_accuracy: 0.8792\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.3881 - accuracy: 0.8623 - val_loss: 0.3349 - val_accuracy: 0.8825\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.3796 - accuracy: 0.8649 - val_loss: 0.3299 - val_accuracy: 0.8817\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.3738 - accuracy: 0.8677 - val_loss: 0.3209 - val_accuracy: 0.8889\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.3662 - accuracy: 0.8709 - val_loss: 0.3698 - val_accuracy: 0.8702\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.3626 - accuracy: 0.8713 - val_loss: 0.3184 - val_accuracy: 0.8888\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.3565 - accuracy: 0.8740 - val_loss: 0.3139 - val_accuracy: 0.8907\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.3526 - accuracy: 0.8764 - val_loss: 0.3130 - val_accuracy: 0.8908\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.3477 - accuracy: 0.8784 - val_loss: 0.3197 - val_accuracy: 0.8906\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.3402 - accuracy: 0.8806 - val_loss: 0.3365 - val_accuracy: 0.8861\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.3414 - accuracy: 0.8802 - val_loss: 0.3163 - val_accuracy: 0.8928\n",
            "\n",
            "Test accuracy:\n",
            "0.8927500247955322\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.6508 - accuracy: 0.7597 - val_loss: 0.3851 - val_accuracy: 0.8600\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.4234 - accuracy: 0.8458 - val_loss: 0.3558 - val_accuracy: 0.8703\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.3736 - accuracy: 0.8611 - val_loss: 0.3385 - val_accuracy: 0.8783\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.3459 - accuracy: 0.8717 - val_loss: 0.3121 - val_accuracy: 0.8875\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.3292 - accuracy: 0.8785 - val_loss: 0.3023 - val_accuracy: 0.8892\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.3189 - accuracy: 0.8811 - val_loss: 0.2960 - val_accuracy: 0.8910\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.3038 - accuracy: 0.8886 - val_loss: 0.2875 - val_accuracy: 0.8992\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.2941 - accuracy: 0.8915 - val_loss: 0.2847 - val_accuracy: 0.8982\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.2846 - accuracy: 0.8929 - val_loss: 0.2851 - val_accuracy: 0.8959\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.2735 - accuracy: 0.8982 - val_loss: 0.2990 - val_accuracy: 0.8925\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.2710 - accuracy: 0.8995 - val_loss: 0.2781 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.2658 - accuracy: 0.9006 - val_loss: 0.2928 - val_accuracy: 0.8939\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.2553 - accuracy: 0.9052 - val_loss: 0.2835 - val_accuracy: 0.9005\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.2507 - accuracy: 0.9046 - val_loss: 0.2873 - val_accuracy: 0.8963\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.2432 - accuracy: 0.9089 - val_loss: 0.2844 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.2384 - accuracy: 0.9086 - val_loss: 0.2758 - val_accuracy: 0.9032\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.2298 - accuracy: 0.9125 - val_loss: 0.2737 - val_accuracy: 0.9047\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.2286 - accuracy: 0.9141 - val_loss: 0.2752 - val_accuracy: 0.9030\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.2252 - accuracy: 0.9138 - val_loss: 0.2751 - val_accuracy: 0.9051\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2196 - accuracy: 0.9180 - val_loss: 0.2830 - val_accuracy: 0.9001\n",
            "\n",
            "Test accuracy:\n",
            "0.9000833630561829\n",
            "Epoch 1/20\n",
            "188/188 - 1s - loss: 0.9974 - accuracy: 0.6194 - val_loss: 0.5671 - val_accuracy: 0.7825\n",
            "\n",
            "Epoch 2/20\n",
            "188/188 - 1s - loss: 0.6153 - accuracy: 0.7736 - val_loss: 0.4931 - val_accuracy: 0.8220\n",
            "\n",
            "Epoch 3/20\n",
            "188/188 - 1s - loss: 0.5364 - accuracy: 0.8063 - val_loss: 0.4651 - val_accuracy: 0.8325\n",
            "\n",
            "Epoch 4/20\n",
            "188/188 - 1s - loss: 0.4928 - accuracy: 0.8246 - val_loss: 0.3975 - val_accuracy: 0.8590\n",
            "\n",
            "Epoch 5/20\n",
            "188/188 - 1s - loss: 0.4564 - accuracy: 0.8367 - val_loss: 0.3868 - val_accuracy: 0.8576\n",
            "\n",
            "Epoch 6/20\n",
            "188/188 - 1s - loss: 0.4361 - accuracy: 0.8426 - val_loss: 0.3778 - val_accuracy: 0.8653\n",
            "\n",
            "Epoch 7/20\n",
            "188/188 - 1s - loss: 0.4156 - accuracy: 0.8524 - val_loss: 0.3619 - val_accuracy: 0.8736\n",
            "\n",
            "Epoch 8/20\n",
            "188/188 - 1s - loss: 0.3993 - accuracy: 0.8561 - val_loss: 0.3694 - val_accuracy: 0.8647\n",
            "\n",
            "Epoch 9/20\n",
            "188/188 - 1s - loss: 0.3820 - accuracy: 0.8627 - val_loss: 0.3410 - val_accuracy: 0.8775\n",
            "\n",
            "Epoch 10/20\n",
            "188/188 - 1s - loss: 0.3715 - accuracy: 0.8662 - val_loss: 0.3475 - val_accuracy: 0.8753\n",
            "\n",
            "Epoch 11/20\n",
            "188/188 - 1s - loss: 0.3605 - accuracy: 0.8709 - val_loss: 0.3780 - val_accuracy: 0.8659\n",
            "\n",
            "Epoch 12/20\n",
            "188/188 - 1s - loss: 0.3518 - accuracy: 0.8737 - val_loss: 0.3217 - val_accuracy: 0.8827\n",
            "\n",
            "Epoch 13/20\n",
            "188/188 - 1s - loss: 0.3427 - accuracy: 0.8764 - val_loss: 0.3252 - val_accuracy: 0.8862\n",
            "\n",
            "Epoch 14/20\n",
            "188/188 - 1s - loss: 0.3346 - accuracy: 0.8802 - val_loss: 0.3031 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 15/20\n",
            "188/188 - 1s - loss: 0.3250 - accuracy: 0.8837 - val_loss: 0.3035 - val_accuracy: 0.8914\n",
            "\n",
            "Epoch 16/20\n",
            "188/188 - 1s - loss: 0.3211 - accuracy: 0.8844 - val_loss: 0.3017 - val_accuracy: 0.8924\n",
            "\n",
            "Epoch 17/20\n",
            "188/188 - 1s - loss: 0.3124 - accuracy: 0.8864 - val_loss: 0.3283 - val_accuracy: 0.8813\n",
            "\n",
            "Epoch 18/20\n",
            "188/188 - 1s - loss: 0.3041 - accuracy: 0.8900 - val_loss: 0.3283 - val_accuracy: 0.8806\n",
            "\n",
            "Epoch 19/20\n",
            "188/188 - 1s - loss: 0.3000 - accuracy: 0.8920 - val_loss: 0.3358 - val_accuracy: 0.8842\n",
            "\n",
            "Epoch 20/20\n",
            "188/188 - 1s - loss: 0.2976 - accuracy: 0.8931 - val_loss: 0.2953 - val_accuracy: 0.8967\n",
            "\n",
            "Test accuracy:\n",
            "0.8967499732971191\n",
            "Epoch 1/20\n",
            "375/375 - 1s - loss: 0.6767 - accuracy: 0.7549 - val_loss: 0.4038 - val_accuracy: 0.8529\n",
            "\n",
            "Epoch 2/20\n",
            "375/375 - 1s - loss: 0.4311 - accuracy: 0.8436 - val_loss: 0.3820 - val_accuracy: 0.8662\n",
            "\n",
            "Epoch 3/20\n",
            "375/375 - 1s - loss: 0.3889 - accuracy: 0.8581 - val_loss: 0.3478 - val_accuracy: 0.8717\n",
            "\n",
            "Epoch 4/20\n",
            "375/375 - 1s - loss: 0.3580 - accuracy: 0.8696 - val_loss: 0.3247 - val_accuracy: 0.8835\n",
            "\n",
            "Epoch 5/20\n",
            "375/375 - 1s - loss: 0.3394 - accuracy: 0.8770 - val_loss: 0.3607 - val_accuracy: 0.8767\n",
            "\n",
            "Epoch 6/20\n",
            "375/375 - 1s - loss: 0.3226 - accuracy: 0.8812 - val_loss: 0.3122 - val_accuracy: 0.8867\n",
            "\n",
            "Epoch 7/20\n",
            "375/375 - 1s - loss: 0.3126 - accuracy: 0.8861 - val_loss: 0.2981 - val_accuracy: 0.8923\n",
            "\n",
            "Epoch 8/20\n",
            "375/375 - 1s - loss: 0.2997 - accuracy: 0.8901 - val_loss: 0.3026 - val_accuracy: 0.8917\n",
            "\n",
            "Epoch 9/20\n",
            "375/375 - 1s - loss: 0.2868 - accuracy: 0.8952 - val_loss: 0.3017 - val_accuracy: 0.8899\n",
            "\n",
            "Epoch 10/20\n",
            "375/375 - 1s - loss: 0.2799 - accuracy: 0.8966 - val_loss: 0.2957 - val_accuracy: 0.8936\n",
            "\n",
            "Epoch 11/20\n",
            "375/375 - 1s - loss: 0.2714 - accuracy: 0.8994 - val_loss: 0.2964 - val_accuracy: 0.8947\n",
            "\n",
            "Epoch 12/20\n",
            "375/375 - 1s - loss: 0.2675 - accuracy: 0.9016 - val_loss: 0.2877 - val_accuracy: 0.8970\n",
            "\n",
            "Epoch 13/20\n",
            "375/375 - 1s - loss: 0.2579 - accuracy: 0.9046 - val_loss: 0.2960 - val_accuracy: 0.8948\n",
            "\n",
            "Epoch 14/20\n",
            "375/375 - 1s - loss: 0.2515 - accuracy: 0.9064 - val_loss: 0.2987 - val_accuracy: 0.8974\n",
            "\n",
            "Epoch 15/20\n",
            "375/375 - 1s - loss: 0.2486 - accuracy: 0.9075 - val_loss: 0.2885 - val_accuracy: 0.8964\n",
            "\n",
            "Epoch 16/20\n",
            "375/375 - 1s - loss: 0.2430 - accuracy: 0.9102 - val_loss: 0.2830 - val_accuracy: 0.8995\n",
            "\n",
            "Epoch 17/20\n",
            "375/375 - 1s - loss: 0.2374 - accuracy: 0.9115 - val_loss: 0.2830 - val_accuracy: 0.8985\n",
            "\n",
            "Epoch 18/20\n",
            "375/375 - 1s - loss: 0.2322 - accuracy: 0.9133 - val_loss: 0.3043 - val_accuracy: 0.8878\n",
            "\n",
            "Epoch 19/20\n",
            "375/375 - 1s - loss: 0.2279 - accuracy: 0.9141 - val_loss: 0.2974 - val_accuracy: 0.8993\n",
            "\n",
            "Epoch 20/20\n",
            "375/375 - 1s - loss: 0.2244 - accuracy: 0.9169 - val_loss: 0.2946 - val_accuracy: 0.8997\n",
            "\n",
            "Test accuracy:\n",
            "0.8997499942779541\n",
            "100%|██████████| 30/30 [06:19<00:00, 12.65s/it, best loss: -0.9027500152587891]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uB8qtrGVbYkM",
        "outputId": "17a26b15-96b5-49f0-c8f5-f417195ae3d4"
      },
      "source": [
        "    print(\"Evalutation of best performing model:\")\r\n",
        "    print(best_model.evaluate(X_test, Y_test))\r\n",
        "    print(\"Best performing model chosen hyper-parameters:\")\r\n",
        "    print(best_run)"
      ],
      "id": "uB8qtrGVbYkM",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Evalutation of best performing model:\n",
            "313/313 [==============================] - 1s 2ms/step - loss: 0.3384 - accuracy: 0.8910\n",
            "[0.33840444684028625, 0.890999972820282]\n",
            "Best performing model chosen hyper-parameters:\n",
            "{'Activation': 0, 'Activation_1': 0, 'Activation_2': 1, 'Dense': 2, 'Dense_1': 3, 'Dense_2': 2, 'Dropout': 0.002343401291026753, 'Dropout_1': 0.6759984371956214, 'Dropout_2': 1, 'Dropout_3': 0.0032498967209000917, 'batch_size': 1, 'choiceval': 0, 'lr': 0, 'lr_1': 0, 'lr_2': 2}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MgFtfEWsxUYE"
      },
      "source": [
        "from keras.layers.normalization import BatchNormalization\r\n",
        "model = Sequential([\r\n",
        "    Dense(512, input_shape=(784,), activation='relu'),\r\n",
        "    Dropout(0.002),\r\n",
        "    Dense(1024, activation='relu'),\r\n",
        "    BatchNormalization(),\r\n",
        "    Dropout(0.675),\r\n",
        "    Dense(512, activation='relu'),\r\n",
        "    BatchNormalization(),\r\n",
        "    Dropout(0.003),\r\n",
        "    Dense(10, activation='softmax')\r\n",
        "])\r\n",
        "model.compile(optimizer='adam',\r\n",
        " loss='categorical_crossentropy',\r\n",
        " metrics=['accuracy'])"
      ],
      "id": "MgFtfEWsxUYE",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qxNIJekRxJFq"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "qxNIJekRxJFq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PyJix3cJGdQ",
        "outputId": "82ffb05c-46c1-404a-fe26-78a58677fd76"
      },
      "source": [
        "model.summary()"
      ],
      "id": "0PyJix3cJGdQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_2 (Dense)              (None, 512)               401920    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1024)              525312    \n",
            "_________________________________________________________________\n",
            "batch_normalization (BatchNo (None, 1024)              4096      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 512)               524800    \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 512)               2048      \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 1,463,306\n",
            "Trainable params: 1,460,234\n",
            "Non-trainable params: 3,072\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SzdYSGP4zfSG",
        "outputId": "76da48bd-5491-49d4-cc46-8111d2a78318"
      },
      "source": [
        "history = model.fit(X_train, Y_train, steps_per_epoch=500, epochs=20, verbose=1, validation_data=(X_val, Y_val)) "
      ],
      "id": "SzdYSGP4zfSG",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "500/500 [==============================] - 4s 4ms/step - loss: 0.7515 - accuracy: 0.7440 - val_loss: 0.4813 - val_accuracy: 0.8303\n",
            "Epoch 2/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.4410 - accuracy: 0.8409 - val_loss: 0.3933 - val_accuracy: 0.8617\n",
            "Epoch 3/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3802 - accuracy: 0.8602 - val_loss: 0.3746 - val_accuracy: 0.8662\n",
            "Epoch 4/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3574 - accuracy: 0.8676 - val_loss: 0.3870 - val_accuracy: 0.8680\n",
            "Epoch 5/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3321 - accuracy: 0.8745 - val_loss: 0.3684 - val_accuracy: 0.8664\n",
            "Epoch 6/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3179 - accuracy: 0.8837 - val_loss: 0.3110 - val_accuracy: 0.8896\n",
            "Epoch 7/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.3047 - accuracy: 0.8860 - val_loss: 0.3323 - val_accuracy: 0.8820\n",
            "Epoch 8/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2950 - accuracy: 0.8908 - val_loss: 0.3269 - val_accuracy: 0.8851\n",
            "Epoch 9/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2763 - accuracy: 0.8959 - val_loss: 0.3482 - val_accuracy: 0.8769\n",
            "Epoch 10/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2703 - accuracy: 0.8973 - val_loss: 0.2959 - val_accuracy: 0.8956\n",
            "Epoch 11/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2573 - accuracy: 0.9021 - val_loss: 0.2996 - val_accuracy: 0.8929\n",
            "Epoch 12/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2527 - accuracy: 0.9044 - val_loss: 0.3128 - val_accuracy: 0.8842\n",
            "Epoch 13/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2461 - accuracy: 0.9059 - val_loss: 0.3055 - val_accuracy: 0.8944\n",
            "Epoch 14/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2381 - accuracy: 0.9123 - val_loss: 0.2859 - val_accuracy: 0.8999\n",
            "Epoch 15/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2219 - accuracy: 0.9155 - val_loss: 0.3227 - val_accuracy: 0.8808\n",
            "Epoch 16/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2220 - accuracy: 0.9164 - val_loss: 0.2932 - val_accuracy: 0.8953\n",
            "Epoch 17/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2198 - accuracy: 0.9164 - val_loss: 0.2942 - val_accuracy: 0.8947\n",
            "Epoch 18/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2131 - accuracy: 0.9191 - val_loss: 0.2942 - val_accuracy: 0.9016\n",
            "Epoch 19/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2081 - accuracy: 0.9218 - val_loss: 0.2913 - val_accuracy: 0.9009\n",
            "Epoch 20/20\n",
            "500/500 [==============================] - 2s 4ms/step - loss: 0.2053 - accuracy: 0.9224 - val_loss: 0.2990 - val_accuracy: 0.9002\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VUuwtpjLz2iY",
        "outputId": "af2efaf1-21ce-4b1b-fa29-d114e2cee756"
      },
      "source": [
        "score = model.evaluate(X_test, Y_test, verbose=0) \r\n",
        "print('Test loss:', score[0]) \r\n",
        "print('Test accuracy:', score[1])"
      ],
      "id": "VUuwtpjLz2iY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test loss: 0.3470429480075836\n",
            "Test accuracy: 0.8840000033378601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bzg8VBCzlxJ"
      },
      "source": [
        ""
      ],
      "id": "2bzg8VBCzlxJ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0Bw4tKK2-xT"
      },
      "source": [
        "By chhosing the best parameters"
      ],
      "id": "R0Bw4tKK2-xT"
    }
  ]
}